{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport torch, torchvision\nimport albumentations\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pickle\nfrom skimage import io\nimport random\nimport copy\nimport cv2\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nfrom pathlib import Path\nfrom time import sleep\n\nfrom torchvision import transforms\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\nfrom matplotlib import colors, pyplot as plt\n%matplotlib inline\n\n# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n# мы будем игнорировать warnings\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RESCALE_SIZE = 224\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\n    DEVICE = torch.device(\"cpu\")\nelse:\n    print('CUDA is available!  Training on GPU ...')\n    DEVICE = torch.device(\"cuda\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, Resize, RandomCrop,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, Flip, OneOf, Compose, Rotate, RandomScale, RandomGridShuffle,\n    RandomContrast, RandomGamma, RandomBrightness, CenterCrop, VerticalFlip,\n    ChannelShuffle, InvertImg, RGBShift, ElasticTransform, Equalize, RandomResizedCrop, ChannelDropout\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_aug1(p=.5):\n    return Compose([\n        RandomRotate90(),\n        HorizontalFlip(),\n        VerticalFlip(),\n        Transpose(),\n        #ElasticTransform(),\n        ChannelShuffle(p = 0.5),\n        RGBShift(r_shift_limit=127, g_shift_limit=127, b_shift_limit=127, p = 0.5),\n        #RandomContrast(),\n        RandomCrop(224,224),\n        Rotate(border_mode=cv2.BORDER_CONSTANT, limit = 45, interpolation=4, p=.8, value = 0),\n        #OneOf([\n        #Rotate(border_mode=1, limit = 45, interpolation=4, p=.5),\n        #Rotate(border_mode=4, limit = 45, interpolation=4, p=.5),\n        #], p=0.9),\n        #ChannelDropout(),\n        #RandomGamma(),\n        #RandomBrightness(),\n        #RandomContrast(),\n        #RandomBrightnessContrast(),\n        #RandomScale(),\n        #IAASharpen(),\n        ChannelDropout(),\n        #Equalize(p=1.),\n        CLAHE(p=1.),\n#        RandomGridShuffle()\n    ], p=p)\ntrain_aug_v1 = train_aug1(1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_aug2(p=.5):\n    return Compose([\n        RandomRotate90(),\n        HorizontalFlip(),\n        VerticalFlip(),\n        Transpose(),\n        #ElasticTransform(),\n        RandomCrop(224,224),\n        #Rotate(border_mode=cv2.BORDER_CONSTANT, limit = 45, interpolation=4, p=.8, value = 0),\n        #RandomContrast(),\n        #OneOf([\n        #Rotate(border_mode=4, limit = 45, interpolation=4, p=.5),\n        #], p=0.9),\n#        OneOf([\n#            ChannelShuffle(p = 0.5),\n#            InvertImg(p=0.5)\n#        ], p=0.5),\n        ChannelShuffle(p = 0.5),\n        RGBShift(r_shift_limit=127, g_shift_limit=127, b_shift_limit=127, p = 0.5),\n#        RandomContrast(),\n        ChannelDropout(),\n        #Equalize(p=1.),\n        CLAHE(p=1.),\n    ], p=p)\ntrain_aug_v2 = train_aug2(1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_aug(p=.5):\n    return Compose([\n        RandomRotate90(),\n        HorizontalFlip(),\n        VerticalFlip(),\n        Transpose(),\n        #Equalize(p=1.),\n        CLAHE(p=1.),\n#        ShiftScaleRotate(shift_limit=0.1, scale_limit = [-0.1, 0], rotate_limit = 0, interpolation=4, p=.5),\n        #RandomGridShuffle(p = 0.3),\n        #RandomBrightnessContrast(p=.5),\n    ], p=p)\nval_aug = val_aug(1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_aug():\n    return CLAHE(p=1.)\ntest_aug = test_aug()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DvsCDataset(Dataset):\n    def __init__(self, files, mode):\n        super().__init__()\n        self.files = files\n        # режим работы\n        self.mode = mode            \n        self.labels = [path.parent.name for path in self.files]\n        self.len_ = len(self.files)\n                      \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image\n  \n    def _get_label(self, idx):\n        if self.mode != 'test':\n            return self.labels[idx]\n\n    def __getitem__(self, index):\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n        ])\n        x = self.load_sample(self.files[index])\n        x = self._prepare_sample(x)\n        x = np.array(x / 255., dtype='float32')\n        x = transform(x)\n        if self.mode == 'test':\n            return x\n        else:\n            label = self.labels[index]\n            y = 0\n            if label == 'cleaned':\n                y = 1\n            return x, y\n        \n    def _prepare_sample(self, image):  \n        if self.mode == 'train':\n            random_value = random.random()\n            if random_value < 0.5:\n                image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n                image = np.array(image)\n                image = train_aug_v1(image=image)['image']\n                \n            else:\n                image = np.array(image)\n                image = train_aug_v2(image=image)['image']\n                \n        if self.mode == 'val':\n            image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n            image = np.array(image)\n            image = val_aug(image=image)['image']\n        if self.mode == 'test':\n            image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n            image = np.array(image)\n            image = test_aug(image=image)['image']\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(inp, title=None, plt_ax=plt, default=False):\n    \"\"\"Imshow для тензоров\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt_ax.imshow(inp)\n    if title is not None:\n        plt_ax.set_title(title)\n    plt_ax.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from os.path import exists\nif not exists('plates'):\n  !unzip -q /kaggle/input/platesv2/plates.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = Path('plates/train')\nTEST_DIR = Path('plates/test')\n\n\ntrain_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at chosen transformations effect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataset = DvsCDataset(train_val_files, mode='val')\ntrain_dataset = DvsCDataset(train_val_files, mode='train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5, ncols=5,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_plate = int(np.random.uniform(0,len(train_val_files)))\n    im_val, label = train_dataset[random_plate]\n    img_label = label\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,len(train_val_files)))\n    im_val, label = val_dataset[random_characters]\n    img_label = label\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in train_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.float().unsqueeze(1).to(DEVICE)\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        for param in model.fc.parameters():\n            loss += 1e-4*torch.sum(torch.abs(param))\n        loss.backward()\n        optimizer.step()\n        preds = torch.round(outputs).long()\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_data += inputs.size(0)\n              \n    train_loss = running_loss / processed_data\n    train_acc = running_corrects.cpu().numpy() / processed_data\n    return train_loss, train_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n\n    for inputs, labels in val_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.float().unsqueeze(1).to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.round(outputs).long()\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n    val_loss = running_loss / processed_size\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(train_dataset, val_dataset, model, epochs, batch_size):\n\n    best_model = None\n    epwi = 0\n    best_val_loss = np.inf\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size , shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    train_acc {t_acc:0.4f} \\\n    val_loss {v_loss:0.4f} val_acc {v_acc:0.4f}\"\n\n    #with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    #opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n    scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min',\n                                    factor=0.1, patience=5, threshold=0.0001, verbose = True,\n                                    threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer = opt, milestones = [5, 10, 15, 20],\n    #                                                 gamma=0.1, last_epoch=-1)\n    #scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n    criterion = nn.BCELoss()\n\n    for epoch in range(epochs):\n        train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n        #print(\"loss\", train_loss)\n\n        val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n        scheduler.step(val_loss)\n        history.append((train_loss, train_acc, val_loss, val_acc))\n        if val_loss < best_val_loss:\n            epwi = 0\n            best_model = copy.deepcopy(model)\n            best_val_loss = val_loss\n        else:\n            epwi += 1\n            \n            '''pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss\n                                           , v_loss=val_loss, t_acc=train_acc\n                                           , v_acc=val_acc))'''\n        print(log_template.format(ep=epoch+1, t_loss=train_loss\n                                       , v_loss=val_loss, t_acc=train_acc\n                                       , v_acc=val_acc))\n        if epwi == 15:\n            break\n            \n    return best_model, history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, test_loader, plot_preds = False):\n    with torch.no_grad():\n        probs = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).tolist()\n            outputs = [it[0] for it in outputs]\n            probs += outputs\n            if plot_preds:\n                for n in range(inputs.shape[0]):\n                    print('True pictute')\n                    imshow(inputs[n].cpu())\n                    plt.show(block=False)\n                    sleep(0.1)\n                    print('prediction:')\n                    print(outputs[n])\n            \n        #probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 200\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = DvsCDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame(columns=['id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs = 0\nrandom.seed(rs)\nnp.random.seed(rs)\ntorch.manual_seed(rs)\ntorch.cuda.manual_seed(rs)\ntorch.backends.cudnn.deterministic = True\nval_set = np.array(train_val_files)\ntrain_dataset = DvsCDataset(np.tile(np.array(train_val_files), 100), mode='train')\nval_dataset = DvsCDataset(np.tile(val_set, 100), mode='val')\n\nmodel = models.resnet34(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\n#model.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(2048, 1), nn.Sigmoid())\nmodel.fc = nn.Sequential(nn.Linear(512, 1),  nn.Sigmoid())\n#model.fc = nn.Sequential(nn.Linear(512, 64), \n#                                 nn.Dropout(0.5), nn.Linear(64, 1), nn.Sigmoid())\nSAVE_PATH = 'best_model_fold.pth'\n\nmodel = model.to(DEVICE)\n#model.load_state_dict(torch.load(SAVE_PATH))\nmodel, history = train(train_dataset, val_dataset, model=model, epochs=EPOCHS, batch_size=BATCH_SIZE)\n\nafter_train_dataset = DvsCDataset(val_set, mode=\"test\")\nafter_train_loader = DataLoader(after_train_dataset, shuffle=False, batch_size=BATCH_SIZE)\n\nafter_train_probs = predict(model, after_train_loader)\n\nfor i in range(val_set.shape[0]):\n    plt.imshow(plt.imread(val_set[i]))\n    plt.show(block=False)\n    sleep(0.1)\n    print(val_set[i])\n    print(after_train_probs[i])\n\nloss, acc, val_loss, val_acc = zip(*history)\nplt.figure(figsize=(15, 9))\nplt.plot(loss, label=\"train_loss\")\nplt.plot(val_loss, label=\"val_loss\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()\nplt.close()\n\nprobs = predict(model, test_loader)\npreds = ['cleaned']*len(probs)\nfor i, it in enumerate(probs):\n    if it <= 0.5:\n        preds[i] = 'dirty'\n\nsubmit['label'] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames = [path.name for path in test_dataset.files]\nsubmit['id'] = test_filenames\nsubmit['id'] = submit.apply(lambda x: x['id'].split('.')[0],axis = 1).astype('int')\nsubmit.head()\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}